import requests
from bs4 import BeautifulSoup
import logging

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def search_exploitdb(query):
    """Search Exploit-DB for known vulnerabilities based on CVE IDs or application names."""
    url = f"https://www.exploit-db.com/search?q={query}"
    
    try:
        logging.info(f"Searching Exploit-DB for query: {query}")
        response = requests.get(url, timeout=10)  # Timeout for the request to prevent hanging
        response.raise_for_status()  # Raise an exception for 4xx or 5xx errors

        # Parse the HTML response
        soup = BeautifulSoup(response.text, 'html.parser')
        results = soup.find_all('div', class_='search-result')

        if not results:
            logging.warning(f"No results found for query: {query}")
            return

        # Process the exploit data and extract relevant information
        for result in results:
            title = result.find('h2').text.strip()
            link = "https://www.exploit-db.com" + result.find('a')['href']
            description = result.find('p').text.strip()

            # Display the results in a user-friendly format
            print(f"Title: {title}")
            print(f"Link: {link}")
            print(f"Description: {description}\n")

    except requests.exceptions.Timeout:
        logging.error("Request timed out. Please try again later.")
    except requests.exceptions.RequestException as e:
        logging.error(f"Error retrieving data: {e}")

# Search for an example vulnerability (e.g., CVE-2023-21716)
if __name__ == '__main__':
    search_query = input("Enter CVE ID or application name to search for: ")
    search_exploitdb(search_query)
